# Netflix-Reviews-Sentiment-Analysis
During this project, I deepened my hands-on experience with various text cleaning processes like tokenization, stop word removal, stemming, lemmatization, handling punctuation and special characters. These steps were crucial in ensuring the quality and accuracy of the data used for training our NLP models.
